{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tyronen/recurrent-rebels/blob/hensel/hensel/hensel_colab.ipynb)\n",
    "\n",
    "# Hensel Model Training with W&B Sweeps\n",
    "\n",
    "This notebook sets up and runs hyperparameter tuning for the Hensel model using Weights & Biases (wandb). The notebook will:\n",
    "1. Set up the environment\n",
    "2. Download required data\n",
    "3. Run hyperparameter optimization using wandb sweeps\n",
    "4. Save and analyze the results\n",
    "\n",
    "First, let's make sure we're using a GPU runtime:\n",
    "- Go to Runtime → Change runtime type\n",
    "- Select GPU from the dropdown\n",
    "- Click Save\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## 4. Analyze Results\n",
    "\n",
    "After the sweep is complete, we can analyze the results and download the best model. The following cells will help you:\n",
    "1. Find the best performing run\n",
    "2. Analyze the hyperparameter importance\n",
    "3. Download the best model\n",
    "4. Plot the learning curves\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## 4. Analyze Results\n",
    "\n",
    "After the sweep is complete, we can analyze the results and download the best model. The following cells will help you:\n",
    "1. Find the best performing run\n",
    "2. Analyze the hyperparameter importance\n",
    "3. Download the best model\n",
    "4. Plot the learning curves\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## 4. Analyze Results\n",
    "\n",
    "After the sweep is complete, we can analyze the results and download the best model. The following cells will help you:\n",
    "1. Find the best performing run\n",
    "2. Analyze the hyperparameter importance\n",
    "3. Download the best model\n",
    "4. Plot the learning curves\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## 4. Analyze Results\n",
    "\n",
    "After the sweep is complete, we can analyze the results and download the best model. The following cells will help you:\n",
    "1. Find the best performing run\n",
    "2. Analyze the hyperparameter importance\n",
    "3. Download the best model\n",
    "4. Plot the learning curves\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## 4. Analyze Results\n",
    "\n",
    "After the sweep is complete, we can analyze the results and download the best model. The following cells will help you:\n",
    "1. Find the best performing run\n",
    "2. Analyze the hyperparameter importance\n",
    "3. Download the best model\n",
    "4. Plot the learning curves\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## 4. Analyze Results\n",
    "\n",
    "After the sweep is complete, we can analyze the results and download the best model. The following cells will help you:\n",
    "1. Find the best performing run\n",
    "2. Analyze the hyperparameter importance\n",
    "3. Download the best model\n",
    "4. Plot the learning curves\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## 4. Analyze Results\n",
    "\n",
    "After the sweep is complete, we can analyze the results and download the best model. The following cells will help you:\n",
    "1. Find the best performing run\n",
    "2. Analyze the hyperparameter importance\n",
    "3. Download the best model\n",
    "4. Plot the learning curves\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## 4. Analyze Results\n",
    "\n",
    "After the sweep is complete, we can analyze the results and download the best model. The following cells will help you:\n",
    "1. Find the best performing run\n",
    "2. Analyze the hyperparameter importance\n",
    "3. Download the best model\n",
    "4. Plot the learning curves\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Hensel Model Training with W&B Sweeps\n",
    "\n",
    "This notebook sets up and runs hyperparameter tuning for the Hensel model using Weights & Biases (wandb). The notebook will:\n",
    "1. Set up the environment\n",
    "2. Download required data\n",
    "3. Run hyperparameter optimization using wandb sweeps\n",
    "4. Save and analyze the results\n",
    "\n",
    "First, let's make sure we're using a GPU runtime:\n",
    "- Go to Runtime → Change runtime type\n",
    "- Select GPU from the dropdown\n",
    "- Click Save\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 1. Environment Setup\n",
    "\n",
    "First, we'll install the required packages and clone our repository.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "%pip install torch torchinfo wandb numpy pandas tqdm tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repository and set up the environment\n",
    "!git clone https://github.com/your-username/recurrent-rebels.git\n",
    "%cd recurrent-rebels\n",
    "\n",
    "# Add the project root to Python path\n",
    "import sys\n",
    "sys.path.append('.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Login to Weights & Biases\n",
    "import wandb\n",
    "wandb.login()  # This will prompt for your API key if not already logged in\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 2. Data Preparation\n",
    "\n",
    "We need three main data files:\n",
    "- `train.npz`: Training dataset\n",
    "- `val.npz`: Validation dataset\n",
    "- `train_vocab.json`: Vocabulary file\n",
    "\n",
    "You can either:\n",
    "1. Upload them from your local machine directly to Colab\n",
    "2. Download them from Google Drive\n",
    "3. Download them from a URL\n",
    "\n",
    "Below are examples for each method:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1: Upload from local machine\n",
    "from google.colab import files\n",
    "\n",
    "# Create data directory\n",
    "!mkdir -p data\n",
    "\n",
    "# Uncomment and run this to upload files from your computer\n",
    "# uploaded = files.upload()\n",
    "# for filename in uploaded.keys():\n",
    "#     !mv \"{filename}\" \"data/{filename}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2: Download from Google Drive\n",
    "from google.colab import drive\n",
    "\n",
    "# Mount Google Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Uncomment and modify paths to copy files from Drive\n",
    "# !cp /content/drive/MyDrive/path_to_data/train.npz data/\n",
    "# !cp /content/drive/MyDrive/path_to_data/val.npz data/\n",
    "# !cp /content/drive/MyDrive/path_to_data/train_vocab.json data/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 3: Download from URL\n",
    "# Uncomment and modify URLs to download files\n",
    "# !wget your_data_url/train.npz -O data/train.npz\n",
    "# !wget your_data_url/val.npz -O data/val.npz\n",
    "# !wget your_data_url/train_vocab.json -O data/train_vocab.json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify data files\n",
    "import os\n",
    "\n",
    "required_files = ['train.npz', 'val.npz', 'train_vocab.json']\n",
    "all_files_present = True\n",
    "\n",
    "for file in required_files:\n",
    "    path = os.path.join('data', file)\n",
    "    if os.path.exists(path):\n",
    "        size_mb = os.path.getsize(path) / (1024 * 1024)\n",
    "        print(f\"✓ {file:<15} found ({size_mb:.1f} MB)\")\n",
    "    else:\n",
    "        print(f\"✗ {file:<15} missing\")\n",
    "        all_files_present = False\n",
    "\n",
    "if not all_files_present:\n",
    "    print(\"\\nPlease ensure all required files are present before proceeding.\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 3. Run Hyperparameter Sweep\n",
    "\n",
    "Now we'll run the hyperparameter optimization using wandb sweeps. The sweep will try different combinations of:\n",
    "- Learning rate\n",
    "- Batch size\n",
    "- Hidden size\n",
    "- Dropout rate\n",
    "- Weight decay\n",
    "- Number of epochs\n",
    "\n",
    "The sweep uses Bayesian optimization to efficiently explore the hyperparameter space.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the sweep configuration and training function\n",
    "from hensel.sweep_config import init_sweep\n",
    "from hensel.train import train\n",
    "\n",
    "# Initialize the sweep\n",
    "sweep_id = init_sweep()\n",
    "print(f\"Sweep initialized with ID: {sweep_id}\")\n",
    "print(f\"\\nView sweep at: https://wandb.ai/{wandb.run.entity}/hensel-model/sweeps/{sweep_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the sweep\n",
    "# You can adjust the number of trials by changing count\n",
    "wandb.agent(sweep_id, function=train, count=20)  # Run 20 trials\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 4. Analyze Results\n",
    "\n",
    "After the sweep is complete, we can analyze the results and download the best model. The following cells will help you:\n",
    "1. Find the best performing run\n",
    "2. Analyze the hyperparameter importance\n",
    "3. Download the best model\n",
    "4. Plot the learning curves\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best run from the sweep\n",
    "api = wandb.Api()\n",
    "sweep = api.sweep(f\"{wandb.run.entity}/hensel-model/{sweep_id}\")\n",
    "best_run = sweep.best_run()\n",
    "\n",
    "print(f\"Best run: {best_run.name}\")\n",
    "print(f\"Best validation loss: {best_run.summary.get('best_val_loss', 'N/A')}\")\n",
    "print(\"\\nBest hyperparameters:\")\n",
    "for key, value in best_run.config.items():\n",
    "    print(f\"{key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the best model\n",
    "best_model_path = os.path.join('models', 'hensel', best_run.name, 'best_model.pth')\n",
    "best_run.file('best_model.pth').download(replace=True)\n",
    "\n",
    "print(f\"Best model downloaded to: {best_model_path}\")\n",
    "\n",
    "# Load and verify the model\n",
    "checkpoint = torch.load(best_model_path)\n",
    "print(\"\\nModel checkpoint contains:\")\n",
    "for key in checkpoint.keys():\n",
    "    print(f\"- {key}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot learning curves\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Get the metrics from the best run\n",
    "history = pd.DataFrame(best_run.scan_history())\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['epoch'], history['train_loss'], label='Train')\n",
    "plt.plot(history['epoch'], history['val_loss'], label='Validation')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Learning Curves')\n",
    "plt.legend()\n",
    "\n",
    "# Plot R² scores\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history['epoch'], history['r2_log'], label='R² (log scale)')\n",
    "plt.plot(history['epoch'], history['r2_real'], label='R² (real scale)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('R²')\n",
    "plt.title('R² Scores')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
