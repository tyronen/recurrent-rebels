{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tyronen/recurrent-rebels/blob/hensel/hensel/hensel_colab.ipynb)\n",
        "\n",
        "# Hensel Model Training with W&B Sweeps\n",
        "\n",
        "This notebook sets up and runs hyperparameter tuning for the Hensel model using Weights & Biases (wandb). The notebook will:\n",
        "1. Set up the environment\n",
        "2. Download required data\n",
        "3. Run hyperparameter optimization using wandb sweeps\n",
        "4. Save and analyze the results\n",
        "\n",
        "**Important:** Make sure you're using a GPU runtime:\n",
        "- Go to Runtime → Change runtime type\n",
        "- Select GPU from the dropdown\n",
        "- Click Save\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 1. Environment Setup\n",
        "\n",
        "First, we'll install the required packages and clone our repository.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "%pip install torch torchinfo wandb numpy pandas tqdm tensorboard matplotlib\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clone the repository and set up the environment\n",
        "!git clone https://github.com/tyronen/recurrent-rebels.git\n",
        "%cd recurrent-rebels\n",
        "!git checkout hensel\n",
        "\n",
        "# Add the project root to Python path\n",
        "import sys\n",
        "sys.path.append('.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Login to Weights & Biases\n",
        "import wandb\n",
        "wandb.login()  # This will prompt for your API key\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 2. Data Preparation\n",
        "\n",
        "We need three main data files:\n",
        "- `train.npz`: Training dataset\n",
        "- `val.npz`: Validation dataset  \n",
        "- `train_vocab.json`: Vocabulary file\n",
        "\n",
        "Choose one of the methods below to get your data:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Method 1: Upload from local machine\n",
        "from google.colab import files\n",
        "\n",
        "# Create data directory\n",
        "!mkdir -p data\n",
        "\n",
        "# Uncomment and run this to upload files from your computer\n",
        "# uploaded = files.upload()\n",
        "# for filename in uploaded.keys():\n",
        "#     !mv \"{filename}\" \"data/{filename}\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Method 2: Download from Google Drive\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Uncomment and modify paths to copy files from Drive\n",
        "# !cp /content/drive/MyDrive/path_to_data/train.npz data/\n",
        "# !cp /content/drive/MyDrive/path_to_data/val.npz data/\n",
        "# !cp /content/drive/MyDrive/path_to_data/train_vocab.json data/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verify data files\n",
        "import os\n",
        "\n",
        "required_files = ['train.npz', 'val.npz', 'train_vocab.json']\n",
        "all_files_present = True\n",
        "\n",
        "for file in required_files:\n",
        "    path = os.path.join('data', file)\n",
        "    if os.path.exists(path):\n",
        "        size_mb = os.path.getsize(path) / (1024 * 1024)\n",
        "        print(f\"✓ {file:<15} found ({size_mb:.1f} MB)\")\n",
        "    else:\n",
        "        print(f\"✗ {file:<15} missing\")\n",
        "        all_files_present = False\n",
        "\n",
        "if not all_files_present:\n",
        "    print(\"\\nPlease ensure all required files are present before proceeding.\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 3. Run Hyperparameter Sweep\n",
        "\n",
        "Now we'll run the hyperparameter optimization using wandb sweeps. The sweep will optimize:\n",
        "- Learning rate\n",
        "- Batch size  \n",
        "- Hidden size\n",
        "- Dropout rate\n",
        "- Weight decay\n",
        "- Number of epochs\n",
        "\n",
        "The sweep uses Bayesian optimization to efficiently explore the hyperparameter space.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import the sweep configuration and training function\n",
        "from hensel.sweep_config import init_sweep\n",
        "from hensel.train import train\n",
        "\n",
        "# Initialize the sweep\n",
        "sweep_id = init_sweep()\n",
        "print(f\"Sweep initialized with ID: {sweep_id}\")\n",
        "print(f\"\\nView sweep at: https://wandb.ai/hensel-model/sweeps/{sweep_id}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run the sweep\n",
        "# You can adjust the number of trials by changing count\n",
        "wandb.agent(sweep_id, function=train, count=20)  # Run 20 trials\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 4. Analyze Results\n",
        "\n",
        "After the sweep is complete, we can analyze the results and visualize the performance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get the best run from the sweep\n",
        "api = wandb.Api()\n",
        "sweep = api.sweep(f\"hensel-model/{sweep_id}\")\n",
        "best_run = sweep.best_run()\n",
        "\n",
        "print(f\"Best run: {best_run.name}\")\n",
        "print(f\"Best validation loss: {best_run.summary.get('val_loss', 'N/A')}\")\n",
        "print(\"\\nBest hyperparameters:\")\n",
        "for key, value in best_run.config.items():\n",
        "    print(f\"{key}: {value}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot learning curves\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Get the metrics from the best run\n",
        "history = pd.DataFrame(best_run.scan_history())\n",
        "\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "# Plot training and validation loss\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.plot(history['epoch'], history['train_loss'], label='Train', alpha=0.8)\n",
        "plt.plot(history['epoch'], history['val_loss'], label='Validation', alpha=0.8)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Learning Curves')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot R² scores\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.plot(history['epoch'], history['r2_log'], label='R² (log scale)', alpha=0.8)\n",
        "plt.plot(history['epoch'], history['r2_real'], label='R² (real scale)', alpha=0.8)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('R²')\n",
        "plt.title('R² Scores')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot MAE\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.plot(history['epoch'], history['mae'], label='MAE', alpha=0.8, color='orange')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('MAE')\n",
        "plt.title('Mean Absolute Error')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print final metrics\n",
        "final_metrics = history.iloc[-1]\n",
        "print(f\"\\nFinal Metrics:\")\n",
        "print(f\"Train Loss: {final_metrics['train_loss']:.4f}\")\n",
        "print(f\"Val Loss: {final_metrics['val_loss']:.4f}\")\n",
        "print(f\"MAE: {final_metrics['mae']:.4f}\")\n",
        "print(f\"R² (log): {final_metrics['r2_log']:.4f}\")\n",
        "print(f\"R² (real): {final_metrics['r2_real']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tyronen/recurrent-rebels/blob/hensel/hensel/hensel_colab.ipynb)\n",
        "\n",
        "# Hensel Model Training with W&B Sweeps\n",
        "\n",
        "This notebook sets up and runs hyperparameter tuning for the Hensel model using Weights & Biases (wandb). The notebook will:\n",
        "1. Set up the environment\n",
        "2. Download required data\n",
        "3. Run hyperparameter optimization using wandb sweeps\n",
        "4. Save and analyze the results\n",
        "\n",
        "**Important:** Make sure you're using a GPU runtime:\n",
        "- Go to Runtime → Change runtime type\n",
        "- Select GPU from the dropdown\n",
        "- Click Save\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
